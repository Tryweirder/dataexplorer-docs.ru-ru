---
title: Обработка дубликатов данных в Azure Data Explorer
description: Эта тема покажет вам различные подходы к обработке дубликатов данных при использовании Azure Data Explorer.
author: orspod
ms.author: orspodek
ms.reviewer: mblythe
ms.service: data-explorer
ms.topic: conceptual
ms.date: 12/19/2018
ms.openlocfilehash: 681bb931f2ccb4291d7e186024ca89168b579e0a
ms.sourcegitcommit: 47a002b7032a05ef67c4e5e12de7720062645e9e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/15/2020
ms.locfileid: "81499050"
---
# <a name="handle-duplicate-data-in-azure-data-explorer"></a>Обработка дубликатов данных в Azure Data Explorer

Устройства, которые отправляют данные в облако, поддерживают локальный кэш данных. В зависимости от размера этих данных они могут храниться в локальном кэше несколько дней или даже месяцев. Вам следует принять меры для защиты аналитических баз данных от неисправных устройств, которые могут повторно отправить кэшированные данные и создать дубликаты в аналитической базе данных. В этой статье описаны актуальные рекомендации по обработке дублирующихся данных в таких сценариях.

Самым правильным решением будет предотвращение дублирования данных. Насколько это возможно, устраните все проблемы выше по конвейеру данных, что позволит сэкономить средства на перемещение данных по конвейеру и ресурсы на устранение дублирующихся данных, уже поступивших в систему. Но и в тех случаях, когда невозможно изменить исходную систему, есть несколько способов устранения проблем.

## <a name="understand-the-impact-of-duplicate-data"></a>Анализ влияния дублирующихся данных

Отслеживайте долю дублирующихся данных. Выяснив, сколько в вашей системе дублирующихся данных, вы сможете понять масштаб этой проблемы и ее влияние на бизнес, что поможет выбрать правильное решение.

Пример запроса, который позволяет определить долю дублирующихся записей.

```kusto
let _sample = 0.01; // 1% sampling
let _data =
DeviceEventsAll
| where EventDateTime between (datetime('10-01-2018 10:00') .. datetime('10-10-2018 10:00'));
let _totalRecords = toscalar(_data | count);
_data
| where rand()<= _sample
| summarize recordsCount=count() by hash(DeviceId) + hash(EventId) + hash(StationId)  // Use all dimensions that make row unique. Combining hashes can be improved
| summarize duplicateRecords=countif(recordsCount  > 1)
| extend duplicate_percentage = (duplicateRecords / _sample) / _totalRecords  
```

## <a name="solutions-for-handling-duplicate-data"></a>Решения для обработки дублирующихся данных

### <a name="solution-1-dont-remove-duplicate-data"></a>Решение #1: Не удаляйте дубликаты данных

Оцените бизнес-требования и допустимый объем дублирующихся данных. Некоторые наборы данных сохраняют работоспособность с определенной долей дублирующихся данных. Если дублирующиеся данные незначительно влияют на работу, их можно просто игнорировать. Отказ от удаления дублирующихся данных позволяет обойтись без дополнительных расходов на процесс приема данных и (или) снижения производительности запросов.

### <a name="solution-2-handle-duplicate-rows-during-query"></a>#2 решения: обработка дубликатов строк во время запроса

Другой вариант — фильтровать дублирующиеся строки данных во время выполнения запроса. Агрегированная [`arg_max()`](kusto/query/arg-max-aggfunction.md) функция может быть использована для фильтрации дублирующих записей и возврата последней записи на основе метки времени (или другого столбца). Этот метод позволяет ускорить прием данных, так как дубликаты удаляются во время выполнения запроса. Кроме того, все записи (в том числе дублирующиеся) доступны для аудита и устранения неполадок. Недостатком использования функции `arg_max` является замедление обработки запроса и повышение нагрузки на ЦП при каждом запросе к данным. В зависимости от объема запрашиваемых данных такое решение может стать неэффективным или потреблять много памяти, и тогда стоит рассмотреть другие варианты.

Следующий пример запроса получает последнюю сохраненную запись по набору столбцов, которые определяют уникальность записей:

```kusto
DeviceEventsAll
| where EventDateTime > ago(90d)
| summarize hint.strategy=shuffle arg_max(EventDateTime, *) by DeviceId, EventId, StationId
```

Этот запрос можно разместить внутри функции, а не просто выполнять в таблице:

```kusto
.create function DeviceEventsView
{
DeviceEventsAll
| where EventDateTime > ago(90d)
| summarize arg_max(EventDateTime, *) by DeviceId, EventId, StationId
}
```

### <a name="solution-3-filter-duplicates-during-the-ingestion-process"></a>решение #3: фильтр дублирует во время процесса приема

Еще один вариант решения — фильтровать все дубликаты в процессе приема данных. Такая система игнорирует дублирующиеся данные при записи в таблицы Kusto. Все данные принимаются в промежуточную таблицу и копируются в целевую таблицу только после удаления дублирующихся строк. Преимуществом этого решения является высокая производительность запросов по сравнению с предыдущим вариантом. К недостаткам следует отнести замедление приема данных и повышение затрат на хранение. Кроме того, это решение работает только в том случае, если дублирование не попадает одновременно. Если существует несколько одновременных водоемов, содержащих дубликаты записей, все они могут быть проглочены, так как процесс deduplication не найдет в таблице никаких существующих записей сопоставления.    

Следующий пример демонстрирует этот метод:

1. Создайте дополнительную таблицу на основе той же схемы:

    ```kusto
    .create table DeviceEventsUnique (EventDateTime: datetime, DeviceId: int, EventId: int, StationId: int)
    ```

1. Создайте функцию, которая фильтрует дублирующиеся записи, используя инвертированное объединение новых записей с полученными ранее.

    ```kusto
    .create function RemoveDuplicateDeviceEvents()
    {
    DeviceEventsAll
    | join hint.strategy=broadcast kind = anti
        (
        DeviceEventsUnique
        | where EventDateTime > ago(7d)   // filter the data for certain time frame
        | limit 1000000   //set some limitations (few million records) to avoid choking-up the system during outage recovery

        ) on DeviceId, EventId, StationId
    }
    ```

    > [!NOTE]
    > Операция объединения потребляет много ресурсов ЦП и повышает общую нагрузку на систему.

1. Задайте [политику обновления](kusto/management/update-policy.md) для таблицы `DeviceEventsUnique`. Политика обновления активируется при добавлении новых данных в таблицу `DeviceEventsAll`. Ядро Kusto автоматически выполняет указанную функцию при создании [экстентов](kusto/management/extents-overview.md). Вся обработка выполняется только для новых данных. Следующая команда создает политику обновления, объединяя исходную таблицу (`DeviceEventsAll`), целевую таблицу (`DeviceEventsUnique`) и функцию `RemoveDuplicatesDeviceEvents`.

    ```kusto
    .alter table DeviceEventsUnique policy update
    @'[{"IsEnabled": true, "Source": "DeviceEventsAll", "Query": "RemoveDuplicateDeviceEvents()", "IsTransactional": true, "PropagateIngestionProperties": true}]'
    ```

    > [!NOTE]
    > Политика обновления продлевает процесс приема, так как он сопровождается фильтрацией данных и двукратным приемом (сначала в таблицу `DeviceEventsAll`, а затем в `DeviceEventsUnique`).

1. Сократите срок хранения данных в таблице `DeviceEventsAll`, чтобы избежать хранения копий данных (необязательно). Выберите количество дней в зависимости от объема данных и продолжительности срока, к течение которого вы хотите хранить данные для устранения неполадок. Вы можете задать срок хранения в `0d` дн., чтобы снизить себестоимость проданных товаров и повысить производительность, ведь в этом случае данные не передаются в хранилище.

    ```kusto
    .alter-merge table DeviceEventsAll policy retention softdelete = 1d
    ```

## <a name="summary"></a>Сводка

Дублирующиеся данные можно обрабатывать несколькими способами. Внимательно оцените доступные варианты с учетом стоимости и производительности учетной записи, чтобы выбрать правильный метод для вашего бизнеса.

## <a name="next-steps"></a>Следующие шаги

> [!div class="nextstepaction"]
> [Написание запросов для обозревателя данных Azure](write-queries.md)
