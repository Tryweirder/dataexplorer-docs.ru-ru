---
title: Прием данных в обозревателе данных Azure
description: Сведения о различных способах приема данных в обозревателе данных Azure.
author: orspod
ms.author: orspodek
ms.reviewer: mblythe
ms.service: data-explorer
ms.topic: conceptual
ms.date: 02/18/2019
ms.openlocfilehash: 8f48499e1b9bb1c67f43ae575a68bb38e314f08e
ms.sourcegitcommit: 47a002b7032a05ef67c4e5e12de7720062645e9e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/15/2020
ms.locfileid: "81497893"
---
# <a name="azure-data-explorer-data-ingestion"></a>Прием данных в обозревателе данных Azure

Прием данных — это процесс, используемый для загрузки записей данных из одного или нескольких источников для создания или обновления таблицы в обозревателе данных Azure. После принятия данные становятся доступными для запроса. На следующей схеме показан сквозной поток работы в Azure Data Explorer, в том числе прием данных.

![Поток данных](media/ingest-data-overview/data-flow.png)

Служба управления данными в обозревателе данных Azure, которая отвечает за прием данных, предоставляет следующие функциональные возможности:

1. **Извлечение данных**. Извлечение данных из внешних источников (концентраторов событий) или считывание запросов на прием из очереди Azure.

1. **Пакетная обработка**. Пакетная обработка данных, поступающих в ту же базу данных и таблицу, для оптимизации пропускной способности приема.

1. **Проверка**: Предварительная проверка и преобразование формата при необходимости.

1. **Управление данными**. Сопоставление схемы, упорядочение, индексирование, кодирование и сжатие данных.

1. **Точка сохранения в потоке приема**. Управление нагрузкой приема в модуле и обработка повторных попыток при временных сбоях.

1. **Фиксация приема данных**. Эта операция делает данные доступными для запроса.

## <a name="ingestion-methods"></a>Методы приема

Обозреватель данных Azure поддерживает несколько методов приема, каждый из которых имеет собственные целевые сценарии, преимущества и недостатки. Azure Data Explorer предлагает конвейеры и соединители для общих служб, приема данных программными средствами с помощью пакетов SDK и прямого доступа к модулю в целях изучения.

### <a name="ingestion-using-pipelines-connectors-and-plugins"></a>Прием с помощью конвейеров, соединителей и подключаемых модулей

Azure Data Explorer сейчас поддерживает:

* Конвейер сетки событий, которым можно управлять с помощью мастера управления на портале Azure. Дополнительные сведения см. в статье [Краткое руководство. Прием больших двоичных объектов Azure в Azure Data Explorer благодаря подписке на уведомления службы "Сетка событий Azure"](ingest-data-event-grid.md).

* Конвейер концентратора событий, которым можно управлять с помощью мастера управления на портале Azure. Дополнительные сведения см. в статье [Краткое руководство. Прием данных из концентратора событий в Azure Data Explorer](ingest-data-event-hub.md).

* Подключаемый модуль Logstash. Дополнительные сведения о подключаемом модуле Logstash см. в статье [Краткое руководство. Прием данных из Logstash в Azure Data Explorer](ingest-data-logstash.md).

* Соединитель Kafka. Дополнительные сведения о соединителе Kafka см. в статье [Краткое руководство. Прием данных из Kafka в Azure Data Explorer](ingest-data-kafka.md).

### <a name="ingestion-using-integration-services"></a>Прием данных с помощью служб интеграции

* Azure Data Factory (ADF), полностью управляемая служба интеграции данных для аналитических рабочих нагрузок в Azure, для копирования данных в Azure Data Explorer с помощью [поддерживаемых хранилищ и форматов данных.](/azure/data-factory/copy-activity-overview#supported-data-stores-and-formats) Для получения дополнительной информации смотрите [данные с фабрики данных Azure на Azure Data Explorer.](/azure/data-explorer/data-factory-load-data)

### <a name="programmatic-ingestion"></a>Прием данных программным образом

Обозреватель данных Azure предоставляет пакеты SDK, которые можно использовать для запросов и приема данных. Прием данных программным образом оптимизирован для снижения затрат на прием путем минимизации количества транзакций с хранилищем во время процесса приема и после него.

**Доступные пакеты SDK и проекты с открытым кодом**.

Kusto предоставляет клиентский пакет SDK, с помощью которого можно принимать и запрашивать данные:

* [Пакет SDK для Python](kusto/api/python/kusto-python-client-library.md)

* [Пакет SDK для .NET](kusto/api/netfx/about-the-sdk.md)

* [Пакет SDK для Java](kusto/api/java/kusto-java-client-library.md)

* [Пакет SDK для Node](kusto/api/node/kusto-node-client-library.md)

* [REST API](kusto/api/netfx/kusto-ingest-client-rest.md)

**Методы приема данных программным образом**:

* Прием данных с помощью службы управления данными Azure Data Explorer (надежный прием данных с высокой пропускной способностью):

    [**Пакетный прием данных**](kusto/api/netfx/kusto-ingest-queued-ingest-sample.md) (предоставляется пакетом SDK). Клиент отправляет данные в хранилище BLOB-объектов Azure (обозначено службой управления данными обозревателя данных Azure) и отправляет уведомление в очередь Azure. Прем пакета — это рекомендуемый метод для надежного недорогого приема большого объема данных.

* Прием данных непосредственно в модуль обозревателя данных Azure (лучше всего подходит для просмотра и создания прототипов):

  * **Влиневая проглатка**: команда управления (.ingest inline), содержащая данные в диапазоне, предназначена для специальных целей тестирования.

  * **Прием из запроса**. Команда управления (.set, .set-or-append, .set-or-replace), указывающая на результаты запроса, используется для создания отчетов или небольших временных таблиц.

  * **Прием из хранилища**. Команда управления (.ingest into) с данными, хранящимися во внешнем хранилище (например, в хранилище BLOB-объектов Azure), которая выполняет эффективный массовый прием данных.

**Задержка для различных методов**:

| Метод | Задержка |
| --- | --- |
| **Встроенный прием** | Немедленно |
| **Прием из запроса** | Время запроса + время обработки |
| **Прием из хранилища** | Время загрузки + время обработки |
| **Прием с постановкой в очередь** | Время пакетной обработки + время обработки |
| |

Время обработки зависит от размера данных. Обработка занимает меньше нескольких секунд. Время пакетной обработки по умолчанию — 5 минут.

## <a name="choosing-the-most-appropriate-ingestion-method"></a>Выбор наиболее подходящего метода приема

Прежде чем начать прием данных, задайте себе следующие вопросы.

* Где находятся мои данные? 
* Каков формат данных и можно ли его изменить? 
* Какие обязательные поля должны запрашиваться? 
* Каковы ожидаемые тома данных и скорость? 
* Сколько типов событий ожидается (показано в виде количества таблиц)? 
* Как часто в схеме событий ожидаются изменения? 
* Сколько узлов будут создавать данные? 
* Какова исходная ОС? 
* Каковы требования к задержке? 
* Можно ли использовать один из существующих управляемых конвейеров приема? 

Для организаций с существующей инфраструктурой, основанных на службе обмена сообщениями, такой как Event Hub и IoT Hub, использование разъема, вероятно, является наиболее подходящим решением. Прием с постановкой в очередь подходит для больших объемов данных.

## <a name="supported-data-formats"></a>Поддерживаемые форматы данных

Для всех методов приема, отличных от приема из очереди, отформатируйте данные так, чтобы Azure Data Explorer мог их проанализировать. 
* Поддерживаемые форматы данных: TXT, CSV, TSV, TSVE, PSV, SCSV, SOH, JSON (линии разделены, многолинейные), Avro, Orc и Parquet. 
* Поддерживает сжатие ЗИП и ГЗИ.

> [!NOTE]
> При приеме данных типы данных определяются на основе целевых столбцов таблицы. Если запись является неполной или поле не может быть проанализировано в необходимом типе данных, соответствующие столбцы таблицы заполняются значениями NULL.

## <a name="ingestion-recommendations-and-limitations"></a>Рекомендации по приему и ограничения

* Эффективная политика хранения получаемых данных является производной от политики хранения базы данных. Дополнительные сведения см. в статье о [политике хранения](kusto/management/retentionpolicy.md). Для приема данных требуется разрешение **Принимающей таблицы** или **Принимающей базы данных**.
* Максимальный размер принимаемого файла составляет 5 ГБ. Для приема мы советуем файлы размером от 100 МБ до 1 ГБ.

## <a name="schema-mapping"></a>Сопоставление схем

Сопоставление схем помогает привязать поля исходных данных к столбцам таблицы назначения.

* [Сопоставление CSV](kusto/management/mappings.md#csv-mapping) (необязательно) работает со всеми форматами на базе рядов. Оно может передаваться в качестве параметра команды приема данных или быть [предварительно создано в таблице](kusto/management/create-ingestion-mapping-command.md) и вызываться из параметра команды приема.
* [Сопоставление JSON](kusto/management/mappings.md#json-mapping) (обязательно) и [сопоставление Avro](kusto/management/mappings.md#avro-mapping) (обязательно) может быть выполнено с помощью параметра команды приема. Их также можно [предварительно создать в таблице](kusto/management/create-ingestion-mapping-command.md) и ссылаться на них с помощью параметра команды приема.

## <a name="next-steps"></a>Следующие шаги

> [!div class="nextstepaction"]
> [Прием данных из концентратора событий в Azure Data Explorer](ingest-data-event-hub.md)

> [!div class="nextstepaction"]
> [Краткое руководство. Прием больших двоичных объектов Azure в Azure Data Explorer благодаря подписке на уведомления службы "Сетка событий Azure"](ingest-data-event-grid.md)

> [!div class="nextstepaction"]
> [Проемные данные от Kafka в Azure Data Explorer](ingest-data-kafka.md)

> [!div class="nextstepaction"]
> [Проем данных с помощью библиотеки Azure Data Explorer Python](python-ingest-data.md)

> [!div class="nextstepaction"]
> [Проем данных с помощью библиотеки узлов Azure Data Explorer](node-ingest-data.md)

> [!div class="nextstepaction"]
> [Прием данных с помощью пакета SDK .NET Standard для Azure Data Explorer (предварительная версия)](net-standard-ingest-data.md)

> [!div class="nextstepaction"]
> [Прием данных из Logstash в Azure Data Explorer](ingest-data-logstash.md)
