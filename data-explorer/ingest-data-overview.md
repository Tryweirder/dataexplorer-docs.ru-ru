---
title: Обзор приема данных обозреватель данных Azure
description: Сведения о различных способах приема данных в обозревателе данных Azure.
author: orspod
ms.author: orspodek
ms.reviewer: tzgitlin
ms.service: data-explorer
ms.topic: conceptual
ms.date: 05/18/2020
ms.openlocfilehash: e6630067cb02f3bf4685e274d2d5d2a6d00a97c5
ms.sourcegitcommit: 1618cbad18f92cf0cda85cb79a5cc1aa789a2db7
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/01/2020
ms.locfileid: "91615042"
---
# <a name="azure-data-explorer-data-ingestion-overview"></a>Обзор приема данных обозреватель данных Azure 

Прием данных — это процесс, который используется для загрузки записей данных из одного или нескольких источников для импорта данных в таблицу в обозреватель данных Azure. После принятия данные становятся доступными для запроса.

На схеме ниже показан сквозной поток для работы в Azure обозреватель данных и показаны различные методы приема.

:::image type="content" source="media/data-ingestion-overview/data-management-and-ingestion-overview.png" alt-text="Обзорная схема приема и управления данными":::

Служба управления данными Azure обозреватель данных, которая отвечает за прием данных, реализует следующий процесс:

Azure обозреватель данных извлекает данные из внешнего источника и считывает запросы из ожидающей очереди Azure. Данные передаются пакетной или потоковой передачей в Диспетчер данных. Пакетные данные, передаваемые в одну и ту же базу данных и таблицу, оптимизируются для пропускной способности приема. Azure обозреватель данных проверяет начальные данные и при необходимости преобразует форматы данных. Дальнейшая обработка данных включает в себя сопоставление схемы, систематизацию, индексацию, кодирование и сжатие данных. Данные сохраняются в хранилище в соответствии с заданной политикой хранения. Затем Диспетчер данных фиксирует данные, принимаемые в подсистему, где они доступны для запроса. 

## <a name="supported-data-formats-properties-and-permissions"></a>Поддерживаемые форматы данных, свойства и разрешения

* **[Поддерживаемые форматы данных](ingestion-supported-formats.md)** 

* **[Свойства приема](ingestion-properties.md)**: свойства, влияющие на способ приема данных (например, добавление тегов, сопоставление, время создания).

* **Разрешения**. для приема данных процессу требуются [разрешения уровня приема базы данных](kusto/management/access-control/role-based-authorization.md). Для выполнения других действий, таких как запрос, может потребоваться разрешение администратора базы данных, пользователя базы данных или разрешения администратора таблицы.

## <a name="batching-vs-streaming-ingestion"></a>Пакетирование и передача потоковой передачи

* Прием пакетной обработки выполняет пакетную обработку данных и оптимизирован для высокой пропускной способности приема. Этот метод является предпочтительным и наиболее производительным типом приема. Данные пакетированы в соответствии со свойствами приема. После этого небольшие пакеты данных объединяются и оптимизируются для быстрого выполнения запросов. Политику [пакетной обработки приема](kusto/management/batchingpolicy.md) можно задать для баз данных или таблиц. По умолчанию максимальное значение пакетной обработки составляет 5 минут, 1000 элементов или общий размер 1 ГБ.

* Прием [потоковой передачи](ingest-data-streaming.md) — это непрерывное получение данных из источника потоковой передачи. Прием потоковой передачи обеспечивает задержку практически в реальном времени для небольших наборов данных на таблицу. Изначально данные поступают в хранилище строк, а затем перемещаются в области хранилища столбцов. Приема потоковой передачи можно выполнить с помощью клиентской библиотеки Azure обозреватель данных или одного из поддерживаемых конвейеров данных. 

## <a name="ingestion-methods-and-tools"></a>Методы и средства приема

Azure обозреватель данных поддерживает несколько методов приема, каждый из которых имеет собственные целевые сценарии. К этим методам относятся средства приема, соединители и подключаемые модули для различных служб, управляемые конвейеры, Программное получение с помощью пакетов SDK и прямой доступ к приему.

### <a name="ingestion-using-managed-pipelines"></a>Прием с использованием управляемых конвейеров

Для организаций, желающих управлять (регулирование, повторные попытки, мониторы, оповещения и многое другое), выполненные внешней службой, использование соединителя, вероятно, является наиболее подходящим решением. Прием с постановкой в очередь подходит для больших объемов данных. Azure обозреватель данных поддерживает следующие Azure Pipelines:

* Служба " **[Сетка событий](https://azure.microsoft.com/services/event-grid/)**". конвейер, который прослушивает службу хранилища Azure и обновляет обозреватель данных Azure для извлечения сведений при возникновении подписанных событий. Дополнительные сведения см. в статье [Краткое руководство. Прием больших двоичных объектов Azure в Azure Data Explorer благодаря подписке на уведомления службы "Сетка событий Azure"](ingest-data-event-grid.md).

* **[Концентратор событий](https://azure.microsoft.com/services/event-hubs/)**. конвейер, передающий события из служб в Azure обозреватель данных. Дополнительные сведения см. в статье [Краткое руководство. Прием данных из концентратора событий в Azure Data Explorer](ingest-data-event-hub.md).

* **[Центр Интернета вещей](https://azure.microsoft.com/services/iot-hub/)**— это конвейер, который используется для передачи данных из поддерживаемых устройств IOT в Azure обозреватель данных. Дополнительные сведения см. в разделе прием [из центра Интернета вещей](ingest-data-iot-hub.md).

* **Фабрика данных Azure (ADF)**— полностью управляемая служба интеграции данных для аналитических рабочих нагрузок в Azure. Фабрика данных Azure подключается к более чем 90 поддерживаемым источникам, чтобы обеспечить эффективную и устойчивую передачу данных. ADF готовит, преобразует и дополняет данные для получения аналитических сведений, которые можно отслеживать разными способами. Эту службу можно использовать как одноразовое решение на периодической временной шкале или запускать с помощью конкретных событий. 
  * [Интеграция azure обозреватель данных с фабрикой данных Azure](data-factory-integration.md).
  * [Используйте фабрику данных Azure для копирования данных из поддерживаемых источников в Azure обозреватель данных](/azure/data-explorer/data-factory-load-data).
  * [Копирование из базы данных в обозреватель данных Azure с помощью шаблона фабрики данных Azure](data-factory-template.md).
  * [Используйте действие команды фабрики данных Azure для запуска команд управления обозреватель данных Azure](data-factory-command-activity.md).

### <a name="ingestion-using-connectors-and-plugins"></a>Прием с помощью соединителей и подключаемых модулей

* **Подключаемый модуль Logstash**см. в статье прием [данных из Logstash в Azure обозреватель данных](ingest-data-logstash.md).

* **Kafka Connector**см. [в статье прием данных из Kafka в Azure обозреватель данных](ingest-data-kafka.md).

* **[Power автоматизируется](https://flow.microsoft.com/)**: автоматизированный конвейер рабочего процесса в Azure обозреватель данных. Power автоматизировать можно использовать для выполнения запроса и предустановки действий с помощью результатов запроса в качестве триггера. См. раздел [Azure обозреватель данных Connector to Power автоматизиру (Предварительная версия)](flow.md).

* **Соединитель Apache Spark**: проект с открытым исходным кодом, который может выполняться в любом кластере Spark. Он реализует источник данных и приемник данных для перемещения данных между кластерами Azure обозреватель данных и Spark. Вы можете создавать быстрые и масштабируемые приложения, предназначенные для сценариев, управляемых данными. Apache Spark см. [в разделе соединитель Azure обозреватель данных](spark-connector.md).

### <a name="programmatic-ingestion-using-sdks"></a>Программное получение с помощью пакетов SDK

Обозреватель данных Azure предоставляет пакеты SDK, которые можно использовать для запросов и приема данных. Прием данных программным образом оптимизирован для снижения затрат на прием путем минимизации количества транзакций с хранилищем во время процесса приема и после него.

**Доступные пакеты SDK и проекты с открытым кодом**

* [Пакет SDK для Python](kusto/api/python/kusto-python-client-library.md)

* [Пакет SDK для .NET](kusto/api/netfx/about-the-sdk.md)

* [пакет SDK для Java](kusto/api/java/kusto-java-client-library.md)

* [Пакет SDK для Node](kusto/api/node/kusto-node-client-library.md)

* [REST API](kusto/api/netfx/kusto-ingest-client-rest.md)

* [API GO](kusto/api/golang/kusto-golang-client-library.md)

### <a name="tools"></a>Инструменты

* Прием **[одного щелчка](ingest-data-one-click.md)**: позволяет быстро получать данные путем создания и настройки таблиц из широкого диапазона исходных типов. При выборе приема одним щелчком автоматически предлагаются таблицы и структуры сопоставления на основе источника данных в Azure обозреватель данных. Одно прием щелчка можно использовать для однократного приема или для определения непрерывного приема через службу "Сетка событий" в контейнере, в который были приняты данные.

* Самое **[освещение](lightingest.md)**: служебная программа командной строки для нерегламентированного приема данных в Azure обозреватель данных. Программа может извлекать исходные данные из локальной папки или из контейнера хранилища BLOB-объектов Azure.

### <a name="kusto-query-language-ingest-control-commands"></a>Команды управления приема языка запросов Kusto

Существует ряд методов, с помощью которых данные могут быть непосредственно приняты в подсистему Engine с помощью команд Kusto запросов Language (ККЛ). Поскольку этот метод обходит службы Управление данными, он подходит только для исследования и создания прототипов. Не используйте этот метод в рабочей среде или в сценариях с большим объемом.

  * **Встроенное**получение. команда управления [.](kusto/management/data-ingestion/ingest-inline.md) прием в подсистеме отправляется в механизм, а данные, которые должны быть приняты, являются частью текста команды. Этот метод предназначен для целей тестирования придумываются.

  * Прием **из запроса**: команда управления [. Set,. append,. Set-или-Append или. Set-OR-REPLACE](kusto/management/data-ingestion/ingest-from-query.md) отправляется в подсистему, при этом данные задаются косвенно в виде результатов запроса или команды.

  * Прием **из хранилища (извлечение)**: команда управления [. прием в](kusto/management/data-ingestion/ingest-from-storage.md) отправляется в подсистему, где данные хранятся во внешнем хранилище (например, хранилище BLOB-объектов Azure), доступном подсистеме и на которые указывает команда.

## <a name="comparing-ingestion-methods-and-tools"></a>Сравнение методов и средств приема

| Имя приема | Тип данных | Максимальный размер файла | Потоковая передача, пакетирование, прямое | Наиболее распространенные сценарии | Рекомендации |
| --- | --- | --- | --- | --- | --- |
| [**Прием одного щелчка**](ingest-data-one-click.md) | * ОКП, JSON | 1 ГБ без сжатия (см. Примечание)| Пакетная обработка в контейнер, локальный файл и большой двоичный объект в режиме прямого приема | 1. Создание схемы таблицы, определение непрерывного приема с помощью сетки событий, массовый прием с контейнером (до 10 000 больших двоичных объектов) | 10 000. BLOB-объекты выбираются случайным образом из контейнера|
| [**LightIngest**](lightingest.md) | Поддерживаются все форматы | 1 ГБ без сжатия (см. Примечание) | Пакетная обработка через DM или Direct прием для подсистемы |  Перенос данных, исторические данные с скорректированными отметками времени приема, массовый прием (без ограничений на размер)| С учетом регистра, с учетом пробела |
| [**ADX Kafka**](ingest-data-kafka.md) | | | | |
| [**ADX Apache Spark**](spark-connector.md) | | | | |
| [**LogStash**](ingest-data-logstash.md) | | | | |
| [**Фабрика данных Azure**](kusto/tools/azure-data-factory.md) | [Поддерживаемые форматы данных](/azure/data-factory/copy-activity-overview#supported-data-stores-and-formats) | неограниченное число * (с ограничениями на ADF) | Пакетная обработка или один триггер ADF | Поддерживает форматы, которые обычно не поддерживаются большими файлами, могут копировать из более чем 90 источников с разрешения на облако | Время приема |
|[**Поток данных Azure**](kusto/tools/flow.md) | | | | Команды приема как часть потока| Должно иметь высокопроизводительное время ответа |
| [**Центр Интернета вещей**](ingest-data-iot-hub-overview.md) | [Поддерживаемые форматы данных](ingest-data-iot-hub-overview.md#data-format)  | Н/Д | Пакетирование, потоковая передача | Сообщения IoT, события IoT, свойства IoT | |
| [**Концентратор событий**](ingest-data-event-hub-overview.md) | [Поддерживаемые форматы данных](ingest-data-event-hub-overview.md#data-format) | Н/Д | Пакетирование, потоковая передача | Сообщения, события | |
| [**Сетка событий**](ingest-data-event-grid-overview.md) | [Поддерживаемые форматы данных](ingest-data-event-grid-overview.md#data-format) | 1 ГБ без сжатия | Пакетная обработка | Непрерывное получение из службы хранилища Azure, внешние данные в службе хранилища Azure | 100 КБ — оптимальный размер файла, используемый для переименования BLOB-объектов и создания большого двоичного объекта |
| [**NET STD**](net-standard-ingest-data.md) | Поддерживаются все форматы | 1 ГБ без сжатия (см. Примечание) | Пакетирование, потоковая передача, прямой | Написание собственного кода в соответствии с потребностями Организации |
| [**Python**](python-ingest-data.md) | Поддерживаются все форматы | 1 ГБ без сжатия (см. Примечание) | Пакетирование, потоковая передача, прямой | Написание собственного кода в соответствии с потребностями Организации |
| [**Node.js**](node-ingest-data.md) | Поддерживаются все форматы | 1 ГБ без сжатия (см. Примечание | Пакетирование, потоковая передача, прямой | Написание собственного кода в соответствии с потребностями Организации |
| [**Java**](kusto/api/java/kusto-java-client-library.md) | Поддерживаются все форматы | 1 ГБ без сжатия (см. Примечание) | Пакетирование, потоковая передача, прямой | Написание собственного кода в соответствии с потребностями Организации |
| [**REST**](kusto/api/netfx/kusto-ingest-client-rest.md) | Поддерживаются все форматы | 1 ГБ без сжатия (см. Примечание) | Пакетирование, потоковая передача, прямой| Написание собственного кода в соответствии с потребностями Организации |
| [**Go**](kusto/api/golang/kusto-golang-client-library.md) | Поддерживаются все форматы | 1 ГБ без сжатия (см. Примечание) | Пакетирование, потоковая передача, прямой | Написание собственного кода в соответствии с потребностями Организации |

> [!Note] 
> При указании ссылки в приведенной выше таблице для приема поддерживается максимальный размер файла, равный 5 ГБ. Для приема мы советуем файлы размером от 100 МБ до 1 ГБ.

## <a name="ingestion-process"></a>Процесс приема

Выбрав наиболее подходящий метод приема для ваших потребностей, выполните следующие действия.

1. **Настройка политики хранения**

    Данные, полученные в таблицу в обозреватель данных Azure, подчиняются действующей политике хранения таблицы. Если политика хранения не задана для таблицы явным образом, она создается на основе политики хранения базы данных. Оперативное хранение — это функция размера кластера и политики хранения. При получении большего объема данных, чем доступное место, первая из данных будет вынуждена использовать принудительное хранение.
    
    Убедитесь, что политика хранения базы данных подходит для ваших нужд. В противном случае явно переопределите ее на уровне таблицы. Дополнительные сведения см. в разделе [Политика хранения](kusto/management/retentionpolicy.md). 
    
1. **Создание таблицы**

    Для приема данных необходимо заранее создать таблицу. Используйте один из следующих методов.
   * Создайте таблицу [с помощью команды](kusto/management/create-table-command.md). 
   * Создание таблицы с помощью [приема одним щелчком](one-click-ingestion-new-table.md).

    > [!Note]
    > Если запись является неполной или поле не может быть проанализировано в необходимом типе данных, соответствующие столбцы таблицы заполняются значениями NULL.

1. **Создать сопоставление схемы**

    [Сопоставление схем](kusto/management/mappings.md) помогает привязывать поля данных источника к столбцам целевой таблицы. Сопоставление позволяет принимать данные из разных источников в одну и ту же таблицу на основе определенных атрибутов. Поддерживаются различные типы сопоставлений: по строкам (CSV, JSON и AVRO) и по столбцам (Parquet). В большинстве методов сопоставления также могут быть [предварительно созданы для таблицы](kusto/management/create-ingestion-mapping-command.md) и ссылаться на них из параметра команды приема.

1. **Задание политики обновления** (необязательно)

   Некоторые сопоставления форматов данных (Parquet, JSON и Avro) поддерживают простые и полезные преобразования во время приема. Когда сценарий требует более сложной обработки во время приема, используйте политику обновления, которая позволяет выполнять упрощенную обработку с помощью команд языка запросов Kusto. Политика обновления автоматически запускает извлечение и преобразование полученных данных в исходной таблице и принимает полученные данные в одну или несколько целевых таблиц. Задайте [политику обновления](kusto/management/update-policy.md).



## <a name="next-steps"></a>Дальнейшие действия

* [Поддерживаемые форматы данных](ingestion-supported-formats.md)
* [Поддерживаемые свойства приема](ingestion-properties.md)
