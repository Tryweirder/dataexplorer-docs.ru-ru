---
title: Экспорт данных в хранилище — Azure обозреватель данных | Документация Майкрософт
description: В этой статье описывается экспорт данных в хранилище в обозреватель данных Azure.
services: data-explorer
author: orspod
ms.author: orspodek
ms.reviewer: rkarlin
ms.service: data-explorer
ms.topic: reference
ms.date: 03/12/2020
ms.openlocfilehash: bd7482abb9c13130d863e9abb73819d9409109ea
ms.sourcegitcommit: c815c6ccf33864e21e1d3daff26a4f077dff88f7
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/21/2020
ms.locfileid: "95012161"
---
# <a name="export-data-to-storage"></a>Экспорт данных в хранилище

Выполняет запрос и записывает первый результирующий набор во внешнее хранилище, указанное в [строке подключения к хранилищу](../../api/connection-strings/storage.md).

**Синтаксис**

`.export`[ `async` ] [ `compressed` ] `to` *Аутпутдатаформат* 
 `(` *StorageConnectionString* [ `,` ...] `)` [ `with` `(` *PropertyName* `=` *propertyvalue* [ `,` ...] `)` ] `<|` *Запрос*

**Аргументы**

* `async`: Если указано, указывает, что команда выполняется в асинхронном режиме.
  Дополнительные сведения о поведении в этом режиме см. ниже.

* `compressed`: Если этот параметр указан, артефакты хранилища выходных данных сжимаются как `.gz` файлы. См `compressionType` . раздел для сжатия файлов Parquet как привязки. 

* *Аутпутдатаформат*: указывает формат данных артефактов хранилища, записанных командой. Поддерживаются следующие значения: `csv` , `tsv` , `json` и `parquet` .

* *StorageConnectionString*: указывает одну или несколько [строк подключения к хранилищу](../../api/connection-strings/storage.md) , которые указывают, в какое хранилище следует записывать данные. (Для масштабируемых операций записи может быть задано более одной строки подключения к хранилищу.) Каждая такая строка подключения должна указывать учетные данные, используемые при записи в хранилище.
  Например, при записи в хранилище BLOB-объектов Azure учетные данные могут быть ключом учетной записи хранения или общим ключом доступа (SAS) с разрешениями на чтение, запись и получение списка больших двоичных объектов.

> [!NOTE]
> Настоятельно рекомендуется экспортировать данные в хранилище, размещенное в том же регионе, что и сам кластер Kusto. Сюда входят экспортируемые данные, которые можно передать в другую облачную службу в других регионах. Операции записи должны выполняться локально, в то время как операции чтения могут выполняться удаленно.

* *PropertyName* / *Propertyvalue*: ноль или несколько необязательных свойств экспорта:

|Свойство        |Type    |Описание                                                                                                                |
|----------------|--------|---------------------------------------------------------------------------------------------------------------------------|
|`sizeLimit`     |`long`  |Предельный размер в байтах одного артефакта хранилища, записываемого (до сжатия). Допустимый диапазон — 100 МБ (по умолчанию).|
|`includeHeaders`|`string`|Для `csv` / `tsv` выходных данных управляет созданием заголовков столбцов. Может быть одним из значений `none` (по умолчанию, строки заголовка не `all` выдаются), (выдача строки заголовка в каждый артефакт хранилища) или `firstFile` (выдача строки заголовка в первый артефакт хранилища).|
|`fileExtension` |`string`|Указывает часть "Extension" артефакта хранилища (например, `.csv` или `.tsv` ). Если используется сжатие, `.gz` будет добавлен и.|
|`namePrefix`    |`string`|Указывает префикс, добавляемый к каждому созданному имени артефакта хранилища. Если значение left не указано, будет использоваться случайный префикс.       |
|`encoding`      |`string`|Указывает, как кодировать текст: `UTF8NoBOM` (по умолчанию) или `UTF8BOM` . |
|`compressionType`|`string`|Указывает используемый тип сжатия. Возможные значения: `gzip` или `snappy`. По умолчанию — `gzip`. `snappy` можно (необязательно) использовать для `parquet` форматирования. |
|`distribution`   |`string`  |Указание распространения ( `single` , `per_node` , `per_shard` ). Если значение равно `single` , один поток будет выполнять запись в хранилище. В противном случае при экспорте будут записываться все узлы, которые выполняют запрос параллельно. См. раздел [оператор Evaluate подключаемого модуля](../../query/evaluateoperator.md). По умолчанию — `per_shard`.
|`distributed`   |`bool`  |Включение и отключение распределенного экспорта. Значение false эквивалентно указанию в `single` подсказке о распространении. Значение по умолчанию — true.
|`persistDetails`|`bool`  |Указывает, что команда должна сохранять свои результаты (см `async` . флаг). По умолчанию принимает значение `true` в асинхронных запусках, но может быть отключено, если вызывающий объект не требует результатов. Значение по умолчанию `false` — в синхронных выполнениях, но может быть включено и. |
|`parquetRowGroupSize`|`int`  |Имеет смысл, только если формат данных — Parquet. Управляет размером группы строк в экспортируемых файлах. Размер группы строк по умолчанию — 100000 записей.|

**Результаты**

Команды возвращают таблицу, описывающую созданные артефакты хранилища.
Каждая запись описывает один артефакт и включает путь хранилища к артефакту и количество записей данных, которые он содержит.

|Path|нумрекордс|
|---|---|
|http://storage1.blob.core.windows.net/containerName/export_1_d08afcae2f044c1092b279412dcb571b.csv|10|
|http://storage1.blob.core.windows.net/containerName/export_2_454c0f1359e24795b6529da8a0101330.csv|15|

**Асинхронный режим**

Если `async` указан флаг, команда выполняется в асинхронном режиме.
В этом режиме команда сразу же возвращает идентификатор операции, а экспорт данных остается в фоновом режиме до завершения. ИДЕНТИФИКАТОР операции, возвращаемый командой, можно использовать для отслеживания хода выполнения и в конечном итоге с помощью следующих команд:

* [. показывать операции](../operations.md#show-operations): отслеживать ход выполнения.
* [. Отображение сведений об операции](../operations.md#show-operation-details): получение результатов выполнения.

Например, после успешного завершения можно получить результаты с помощью:

```kusto
.show operation f008dc1e-2710-47d8-8d34-0d562f5f8615 details
```

**Примеры** 

В этом примере Kusto выполняет запрос, а затем экспортирует первый набор записей, созданный запросом, в один или несколько сжатых больших двоичных объектов CSV.
Метки имен столбцов добавляются в качестве первой строки для каждого большого двоичного объекта.

```kusto 
.export
  async compressed
  to csv (
    h@"https://storage1.blob.core.windows.net/containerName;secretKey",
    h@"https://storage1.blob.core.windows.net/containerName2;secretKey"
  ) with (
    sizeLimit=100000,
    namePrefix=export,
    includeHeaders=all,
    encoding =UTF8NoBOM
  )
  <| myLogs | where id == "moshe" | limit 10000
```

## <a name="failures-during-export-commands"></a>Сбои во время выполнения команд экспорта

Во время выполнения команды экспорта могут быть неустранимыми. [Непрерывный экспорт](continuous-data-export.md) автоматически попытается выполнить команду. Стандартные команды экспорта ([Экспорт в хранилище](export-data-to-storage.md), [экспорт во внешнюю таблицу](export-data-to-an-external-table.md)) не выполняют повторные попытки.

*  При сбое команды экспорта артефакты, которые уже были записаны в хранилище, не удаляются. Эти артефакты будут храниться в хранилище. Если команда завершается неудачно, предположим, что экспорт неполон, даже если были записаны некоторые артефакты. 
* Самый лучший способ отследить завершение команды и артефакты, экспортированные после успешного завершения, — с помощью команд [. показывать операции](../operations.md#show-operations) и [. Показывать подробности операции](../operations.md#show-operation-details) .

### <a name="storage-failures"></a>Сбои хранилища

По умолчанию команды экспорта распределены таким, что в хранилище может быть много параллельных операций записи. Уровень распределения зависит от типа команды экспорта:
* Стандартное распределение для обычной `.export` команды — это `per_shard` , то есть все [экстенты](../extents-overview.md) , содержащие данные для одновременного экспорта записи в хранилище. 
* Распределением по умолчанию для команд [экспорта во внешнюю таблицу](export-data-to-an-external-table.md) является, то есть `per_node` параллелизм — это количество узлов в кластере.

Если число экстентов или узлов велико, это может привести к высокой нагрузке на хранилище, что приводит к регулированию хранилища или ошибкам временного хранилища. Следующие предложения могут устранить эти ошибки (в порядке приоритета):

* Увеличьте количество учетных записей хранения, предоставленных команде Export или [внешнему определению таблицы](../external-tables-azurestorage-azuredatalake.md) (нагрузка будет равномерно распределена между учетными записями).
* Сократите параллелизм, задав указание распределения `per_node` (см. раздел свойства команды).
* Сократите число одновременно экспортируемых узлов, задав для [Свойства запроса клиента](../../api/netfx/request-properties.md) `query_fanout_nodes_percent` требуемый параллелизм (процент узлов). Это свойство может быть задано в составе запроса экспорта. Например, следующая команда ограничит число узлов, одновременно записывающих в хранилище, до 50% узлов кластера:

    ```kusto
    .export async  to csv
        ( h@"https://storage1.blob.core.windows.net/containerName;secretKey" ) 
        with
        (
            distribuion="per_node"
        ) 
        <| 
        set query_fanout_nodes_percent = 50;
        ExportQuery
    ```

* При экспорте в секционированную внешнюю таблицу задание `spread` / `concurrency` свойств может привести к сокращению параллелизма (см. подробные сведения в [свойствах команды](export-data-to-an-external-table.md#syntax)).
* Если ни одна из описанных выше задач не позволяет полностью отключить распространение, присвоив `distributed` свойству значение false, но это не рекомендуется, так как это может значительно повлиять на производительность команды.
