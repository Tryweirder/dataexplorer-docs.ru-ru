---
title: .ingest в команду (вытягивание данных из хранилища) - Azure Data Explorer Документы Майкрософт
description: В этой статье описано ,ingest в команде (вытащите данные из хранилища) в Azure Data Explorer.
services: data-explorer
author: orspod
ms.author: orspodek
ms.reviewer: rkarlin
ms.service: data-explorer
ms.topic: reference
ms.date: 03/24/2020
ms.openlocfilehash: 1f304f9dc064094c6d55cb32f3fb453f32114979
ms.sourcegitcommit: 47a002b7032a05ef67c4e5e12de7720062645e9e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/15/2020
ms.locfileid: "81521443"
---
# <a name="the-ingest-into-command-pull-data-from-storage"></a>.ingest в команду (вытащить данные из хранилища)

Команда `.ingest into` попадает в таблицу, "вытягивая" данные из одного или нескольких артефактов облачного хранилища.
Например, команда может получить 1000 csV-форматированных капли из Хранилища Azure Blob, разобрать их и утилизировать их вместе в одну целевую таблицу.
Данные присваиваемы к таблице, не затрагивая существующие записи и не изменяя схему таблицы.

**Синтаксис**

`.ingest``into` `table` *ТаблицаИмя* `with` `(` `,` `=` *IngestionPropertyValue* *IngestionPropertyName* *SourceDataLocator* SourceDataLocator - IngestionPropertyName IngestionPropertyValue`async` `)`]

**Аргументы**

* `async`: Если указано, команда немедленно вернется и продолжит проглатывание в фоновом режиме. Результаты команды будут включать `OperationId` значение, которое затем `.show operation` может быть использовано с командой для получения состояния завершения приема и результатов.
  
* *TableName*: Название таблицы для глотания данных.
  Имя таблицы всегда относительно базы данных в контексте, и ее схема представляет собой схему, которая будет предполагать для данных, если не предусмотрен объект отображения схемы.

* *SourceDataLocator*: Буквальный `string`типа , или запятой разграничения список таких буквальных окруженных `(` и `)` символов, указывая на хранение артефактов, содержащих данные тянуть. Смотрите [строки подключения к хранилищу.](../../api/connection-strings/storage.md)

> [!NOTE]
> Настоятельно рекомендуется использовать [запутанные строки буквальные](../../query/scalar-data-types/string.md#obfuscated-string-literals) для *SourceDataPointer,* который включает в себя фактические учетные данные в нем.
> Служба будет обязательно скраб учетных данных в своих внутренних следов, сообщений об ошибках и т.д.

* *IngestionPropertyName*, *IngestionPropertyValue*: Любое количество [свойств приема,](https://docs.microsoft.com/azure/data-explorer/ingestion-properties) которые влияют на процесс приема.

**Результаты**

Результатом команды является таблица с таким количеством записей, сколько и осколков данных ("объемы"), генерируемых командой.
Если не были созданы осколки данных, одна запись возвращается с пустым (нулевой стоимостью) идентификатором размера.

|Имя       |Тип      |Описание                                                                |
|-----------|----------|---------------------------------------------------------------------------|
|ExtentId   |`guid`    |Уникальный идентификатор для осколок данных, сгенерированный командой.|
|ПунктЗагружен |`string`  |Один или несколько артефактов хранения, которые связаны с этой записью.             |
|Duration   |`timespan`|Сколько времени потребовалось для выполнения приема.                                     |
|HasErrors  |`bool`    |Является ли эта запись отказом при поимке или нет.                |
|ОперацияId|`guid`    |Уникальный идентификатор, представляющий операцию. Может быть использован `.show operation` с командой.|

**Замечания**

Эта команда не изменяет схему попадающей в таблицу.
При необходимости данные "принудятся" к этой схеме во время приема, а не наоборот (дополнительные столбцы игнорируются, а отсутствующие столбцы рассматриваются как нулевые значения).

**Примеры**

Следующий пример поручает движку прочитать две капли из Azure Blob Storage в `T`качестве файлов CSV и задействовать их содержимое в таблице. Представляет `...` собой общую подпись доступа Azure Storage (SAS), которая дает доступ к считыванию к каждому кабелю. Обратите внимание также на использование запутанных `h` строк (перед значениями строки), чтобы гарантировать, что SAS никогда не записывается.

```kusto
.ingest into table T (
    h'https://contoso.blob.core.windows.net/container/file1.csv?...',
    h'https://contoso.blob.core.windows.net/container/file2.csv?...'
)
```

Следующий пример — глотание данных из Azure Data Lake Storage Gen 2 (ADLSv2). Учетные данные,`...`используемые здесь () являются учетными данными учетной записи хранилища (общий ключ), и мы используем запутывание строки только для секретной части строки соединения.

```kusto
.ingest into table T (
  'abfss://myfilesystem@contoso.dfs.core.windows.net/path/to/file1.csv;'
    h'...'
)
```

Следующий пример приводит один файл из хранилища озер данных Azure (ADLS).
Он использует учетные данные пользователя для доступа к ADLS (так что нет необходимости рассматривать хранилище URI как содержащий секрет). Он также показывает, как указать свойства приема.

```kusto
.ingest into table T ('adl://contoso.azuredatalakestore.net/Path/To/File/file1.ext;impersonate')
  with (format='csv')
```

