---
title: Библиотека клиентов Kusto Ingest - Лучшие практики - Azure Data Explorer (ru) Документы Майкрософт
description: В этой статье описывается библиотека клиентов Kusto Ingest - лучшие практики в Azure Data Explorer.
services: data-explorer
author: orspod
ms.author: orspodek
ms.reviewer: rkarlin
ms.service: data-explorer
ms.topic: reference
ms.date: 08/16/2019
ms.openlocfilehash: e28ec3f99abe4163b83721d753da98c0035d1e46
ms.sourcegitcommit: 47a002b7032a05ef67c4e5e12de7720062645e9e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/15/2020
ms.locfileid: "81523704"
---
# <a name="kusto-ingest-client-library---best-practices"></a>Библиотека клиентов Kusto Ingest - Лучшие практики

## <a name="choosing-the-right-ingestclient-flavor"></a>Выбор правильного вкуса IngestClient
Использование [Kusto'UudIngestClient](kusto-ingest-client-reference.md#interface-ikustoqueuedingestclient) является рекомендуемым режимом проглатывания данных. Далее описывается, почему это происходит:
* Прямое проглатывание невозможно во время простоя Kusto Engine (например, во время развертывания), в то время как в режиме очереди запросы сохраняются в очереди Azure, и служба управления данными будет повторно пытаться при необходимости.
* Служба управления данными несет ответственность за то, чтобы не перегружать двигатель запросами на проглатывание. Преодоление этого элемента управления (например, использование прямого приема) может серьезно повлиять на производительность двигателя, как при поглашении, так и на запросе.
* Управление данными агрегирует несколько запросов на использование для оптимизации размера первоначального осколок (размер), который будет создан.
* Существует удобный способ получить обратную связь о каждом проглатывания - будь то удалось или нет.

## <a name="tracking-ingest-operation-status"></a>Отслеживание состояния операции ingest
[Отслеживание состояния операции](kusto-ingest-client-status.md#tracking-ingestion-status-kustoqueuedingestclient) является полезной особенностью в Kusto, однако, включение его на успех отчетности могут быть легко злоупотреблять в той степени, где это будет калечить ваш сервис.<BR>

> [!WARNING]
> Следует избегать включения положительных уведомлений для каждого запроса на использование больших потоков данных, так как это создает чрезвычайную нагрузку на базовые ресурсы xStore, > что может привести к увеличению задержки приема и даже полной невосприимчивости кластера.

## <a name="optimizing-for-throughput"></a>Оптимизация пропускной всей вха
* Загласывание работает лучше всего (т.е. потребляет наименьшие ресурсы во время приема, производит наиболее COGS оптимизированных данных, и приводит к наиболее эффективных артефактов данных), если сделано в больших кусков. Как правило, мы рекомендуем клиентам, которые глотать данные с библиотекой Kusto.Ingest или непосредственно в движок, отправлять данные партиями **по 100 МБ до 1 ГБ (несжатые)**
* Верхний предел важен при работе непосредственно с двигателем Kusto, чтобы помочь уменьшить объем `KustoQueuedIngestClient` памяти, используемой в процессе приема (при использовании класса, слишком большие блоки данных будут разделены на клиента на меньшие части, и небольшие куски будут агрегированы в определенной степени, прежде чем достичь Kusto Engine)
* Нижний предел по размеру проглоченных данных также имеет важное значение, хотя и менее важное значение. Проглочение данных небольшими партиями то и дело совершенно нормально, хотя и немного менее эффективно, чем с помощью больших партий. `KustoQueuedIngestClient`класс также решает проблему для клиентов, которым необходимо глотать большие объемы данных и не может их пакетные на большие куски перед отправкой их в Кусто

## <a name="factors-impacting-ingestion-throughput"></a>Факторы, влияющие на пропускную пропускную выемку
Несколько факторов могут повлиять на пропускную выемку. При планировании трубопровода для приема в Кусто убедитесь, что необходимо оценить следующие моменты, которые могут иметь значительные последствия для ваших COGs.
* Формат данных - CSV является самым быстрым форматом для глотания, JSON, как правило, занимает x2 или x3 дольше для того же объема данных
* Ширина таблицы - убедитесь, что вы только глотать данные вам действительно нужно, как в целом таблица, тем больше столбцов будут закодированы и проиндексированы, следовательно, ниже пропускная способность.
    Вы можете контролировать, какие поля попадают в попадая в систему, предоставляя отображение.
* Местоположение исходных данных - избегая кросс-региона считывает ускоряет проглатывание
* Нагрузка на кластер - когда кластер испытывает высокую нагрузку запроса, пропускные работы займут больше времени, что позволит сократить пропускную выливку
* Шаблон приема - прием в оптимальном режиме, когда кластер подается с партиями до 1 `KustoQueuedIngestClient`ГБ (позаботься с помощью)

## <a name="optimizing-for-cogs"></a>Оптимизация для COGS
Используя клиентские библиотеки Kusto для того, чтобы глотать данные в Kusto, мы призываем наших клиентов пересмотреть свою тактику приема и принять во внимание недавние (осень 2017) изменения в ценах на хранение Azure, которые сделали транзакции blob значительно дороже ( x100).
<BR>
Важно понимать, что чем больше фрагментов данных (файлов/blobs/streams), которые вы отправляете в Кусто, тем больше ваш ежемесячный счет будет получать.
Если вы будете следовать следующим рекомендациям, вы сможете лучше контролировать ваши затраты на заглаткку Kusto:
* **Предпочитаюгло глотать большие куски данных (до 1 ГБ несжатых данных)**<br>
    Многие команды пытаются достичь низкой задержки, прогуливая десятки миллионов крошечных кусков данных, что является крайне неэффективным и очень дорогостоящим.<br>
    Любая партия на стороне клиента поможет. 
* **Убедитесь, что вы предоставляете клиенту Kusto.Ingest точный размер несжатых данных**<br>
    Невыполнение этого поступка может привести к тому, что Kusto будет выполнять дополнительные транзакции хранения.
* **Избегайте** отправки данных `FlushImmediately` для приема `true`с флагом установить, или отправки небольших кусков с `ingest-by` / `drop-by` тегами набора.<br>
    Использование этих данных предотвращает правильное агрегирование данных во время приема данных и приводит к ненужным операциям хранения после приема, что влияет на COGS.<br>
    Кроме того, использование этих чрезмерно может привести к ухудшившему проглатыванию и/или производительности запроса в кластере.<br>
    